{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7d0a88a0",
   "metadata": {},
   "source": [
    "# **ETL RETAIL DATA**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab418fe8",
   "metadata": {},
   "source": [
    "## **1. Extraction**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8533c223",
   "metadata": {},
   "source": [
    "___\n",
    "### *Imports and Setting Seeds*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "467d7a3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import random\n",
    "from datetime import datetime, timedelta\n",
    "from faker import Faker\n",
    "\n",
    "# ===== Reproducibility =====\n",
    "# Fix the randomness so the output is the same every time  the script runs\n",
    "np.random.seed(42)\n",
    "random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dd5cece",
   "metadata": {},
   "source": [
    "#### *Explanation:*\n",
    "\n",
    "Import needed libraries. Set seeds so random functions produce the same results every run (important for debugging and reproducibility).\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2eca5de1",
   "metadata": {},
   "source": [
    "### *Configuration / Constants*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6ea46c51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== Config =====\n",
    "NUM_ROWS = 1000           # Number of rows (records) to generate\n",
    "NUM_CUSTOMERS = 100       # Number of unique customers\n",
    "START_DATE = datetime(2023, 8, 12)   # Start date for invoices\n",
    "END_DATE = datetime(2025, 8, 11)     # End date for invoices\n",
    "\n",
    "# Countries for customers\n",
    "COUNTRIES = [\"United Kingdom\", \"Germany\", \"France\", \"Spain\", \"Netherlands\", \"Italy\", \"Norway\", \"Portugal\"]\n",
    "\n",
    "# List of products (StockCode, Description, Category)\n",
    "PRODUCTS = [\n",
    "    (\"E001\", \"Wireless Mouse\", \"Electronics\"),\n",
    "    (\"E002\", \"Bluetooth Headphones\", \"Electronics\"),\n",
    "    (\"E003\", \"Smartphone Charger\", \"Electronics\"),\n",
    "    (\"C001\", \"Men's T-Shirt\", \"Clothing\"),\n",
    "    (\"C002\", \"Women's Jeans\", \"Clothing\"),\n",
    "    (\"C003\", \"Baseball Cap\", \"Clothing\"),\n",
    "    (\"H001\", \"Ceramic Mug\", \"Home Goods\"),\n",
    "    (\"H002\", \"Wall Clock\", \"Home Goods\"),\n",
    "    (\"H003\", \"LED Desk Lamp\", \"Home Goods\"),\n",
    "    (\"T001\", \"Stuffed Bear\", \"Toys\"),\n",
    "    (\"T002\", \"Building Blocks Set\", \"Toys\"),\n",
    "    (\"T003\", \"RC Car\", \"Toys\"),\n",
    "]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc9e7a77",
   "metadata": {},
   "source": [
    "#### *Explanation:*\n",
    "\n",
    "Define constants such as the number of rows, number of customers, date range, list of countries, and product details to be used throughout the data generation process.\n",
    "\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f79fb68",
   "metadata": {},
   "source": [
    "\n",
    "### *Function to Generate Random Invoice Dates*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "53de899b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_date(start_date, end_date):\n",
    "    \"\"\"Generate a random datetime between start and end dates.\"\"\"\n",
    "    delta = end_date - start_date\n",
    "    return start_date + timedelta(\n",
    "        days=random.randint(0, delta.days),\n",
    "        seconds=random.randint(0, 86400)  # seconds in a day\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "377e42fc",
   "metadata": {},
   "source": [
    "#### *Explanation:*\n",
    "\n",
    "Create a helper function to generate random dates between the specified start and end dates for invoice timestamps.\n",
    "\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3534a86",
   "metadata": {},
   "source": [
    "### *Generate Base Synthetic Dataset*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fa1cd90e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_base_data(num_rows):\n",
    "    \"\"\"Generate synthetic retail data with given number of rows.\"\"\"\n",
    "    data = []\n",
    "    for _ in range(num_rows):\n",
    "        invoice_no = f\"INV{random.randint(10000, 99999)}\"   # Random invoice number\n",
    "        stock_code, description, category = random.choice(PRODUCTS)  # Random product info\n",
    "        quantity = random.randint(1, 50)                      # Quantity between 1 and 50\n",
    "        invoice_date = random_date(START_DATE, END_DATE)     # Random invoice date\n",
    "        unit_price = round(random.uniform(1, 100), 2)        # Unit price between 1 and 100\n",
    "        customer_id = f\"CUST{random.randint(1, NUM_CUSTOMERS)}\"  # Random customer ID\n",
    "        country = random.choice(COUNTRIES)                    # Random country\n",
    "        data.append([invoice_no, stock_code, description, category, quantity, invoice_date, unit_price, customer_id, country])\n",
    "    \n",
    "    columns = [\"InvoiceNo\", \"StockCode\", \"Description\", \"Category\", \"Quantity\", \"InvoiceDate\", \"UnitPrice\", \"CustomerID\", \"Country\"]\n",
    "    return pd.DataFrame(data, columns=columns)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fb3f494",
   "metadata": {},
   "source": [
    "#### *Explanation:*\n",
    "\n",
    "Generate the main synthetic dataset with random invoices, product info, quantities, invoice dates, prices, customer IDs, and countries.\n",
    "\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da422064",
   "metadata": {},
   "source": [
    "### *Inject Missing Values*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fa97bcbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def inject_missing_values(df, desc_frac=0.02, country_frac=0.01):\n",
    "    \"\"\"Randomly replace some 'Description' and 'Country' values with NaN.\"\"\"\n",
    "    df.loc[df.sample(frac=desc_frac).index, \"Description\"] = np.nan\n",
    "    df.loc[df.sample(frac=country_frac).index, \"Country\"] = np.nan\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81d84c7a",
   "metadata": {},
   "source": [
    "#### *Explanation:*\n",
    "\n",
    "Simulate data imperfections by injecting missing values randomly into the 'Description' and 'Country' columns to mimic real-world dirty data.\n",
    "\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a868a803",
   "metadata": {},
   "source": [
    "### *Inject Outliers*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "54ca6a4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def inject_outliers(df, neg_qty_frac=0.01, zero_price_frac=0.01):\n",
    "    \"\"\"Inject outliers: negative quantity and zero prices.\"\"\"\n",
    "    df.loc[df.sample(frac=neg_qty_frac).index, \"Quantity\"] *= -1  # Negative quantity (returns)\n",
    "    df.loc[df.sample(frac=zero_price_frac).index, \"UnitPrice\"] = 0  # Zero price (data error)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e075c02",
   "metadata": {},
   "source": [
    "#### *Explanation:*\n",
    "\n",
    "Introduce data anomalies by randomly making some quantities negative and unit prices zero, representing common outlier issues.\n",
    "\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c49d61c1",
   "metadata": {},
   "source": [
    "### *Save DataFrame to CSV*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ba37b513",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_dataset(df, filename):\n",
    "    \"\"\"Save DataFrame to a CSV file.\"\"\"\n",
    "    df.to_csv(filename, index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f5055c9",
   "metadata": {},
   "source": [
    "#### *Explanation:*\n",
    "\n",
    "Save the generated DataFrame to a CSV file for persistence and later use.\n",
    "\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "166ad4be",
   "metadata": {},
   "source": [
    "### *Generate Customer Names with Faker*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6c8a3a53",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_customer_names(num_customers):\n",
    "    \"\"\"Generate fake customer names mapped by CustomerID.\"\"\"\n",
    "    fake = Faker()\n",
    "    return {f\"CUST{i}\": fake.name() for i in range(1, num_customers + 1)}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f940b87",
   "metadata": {},
   "source": [
    "#### *Explanation:*\n",
    "\n",
    "Use the Faker library to generate realistic and unique customer names, mapped one-to-one with customer IDs.\n",
    "\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c9218b4",
   "metadata": {},
   "source": [
    "### *Assign Customer Names to DataFrame*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "65693a6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def assign_customer_names(df, customer_names):\n",
    "    \"\"\"Add 'CustomerName' column by mapping CustomerID.\"\"\"\n",
    "    df['CustomerName'] = df['CustomerID'].map(customer_names)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ebabb7d",
   "metadata": {},
   "source": [
    "#### *Explanation:*\n",
    "\n",
    "Add a new column 'CustomerName' to the DataFrame by mapping existing customer IDs to the generated customer names.\n",
    "\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e84a16a",
   "metadata": {},
   "source": [
    "### *Pipeline Execution (Putting It All Together)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "099571e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  InvoiceNo StockCode           Description     Category  Quantity  \\\n",
      "0  INV93810      E002  Bluetooth Headphones  Electronics         2   \n",
      "1  INV98696      T003                RC Car         Toys        35   \n",
      "2  INV38657      C001         Men's T-Shirt     Clothing        33   \n",
      "3  INV38893      H002            Wall Clock   Home Goods        38   \n",
      "4  INV54597      C002         Women's Jeans     Clothing        10   \n",
      "\n",
      "           InvoiceDate  UnitPrice CustomerID  Country    CustomerName  \n",
      "0  2024-05-19 08:54:58      23.10     CUST95  Germany  Nathaniel Ross  \n",
      "1  2023-11-09 21:29:57      42.77      CUST4  Germany   Craig Perkins  \n",
      "2  2025-04-19 00:57:58      56.56     CUST92   Norway    Ruben Murphy  \n",
      "3  2024-05-22 00:14:11      76.12     CUST21   Norway    Lance Harris  \n",
      "4  2024-03-19 12:15:18      11.12     CUST49  Germany    Stacie Allen  \n"
     ]
    }
   ],
   "source": [
    "df = generate_base_data(NUM_ROWS)        # Step 1: Generate base data\n",
    "df = inject_missing_values(df)           # Step 2: Add missing values\n",
    "df = inject_outliers(df)                  # Step 3: Add outliers\n",
    "\n",
    "# Convert InvoiceDate to string for saving to CSV\n",
    "df[\"InvoiceDate\"] = df[\"InvoiceDate\"].astype(str)\n",
    "\n",
    "NUM_CUSTOMERS = df['CustomerID'].nunique()  # Count unique customers\n",
    "\n",
    "customer_names = generate_customer_names(NUM_CUSTOMERS)  # Generate names\n",
    "df = assign_customer_names(df, customer_names)           # Assign names to df\n",
    "\n",
    "save_dataset(df, \"synthetic_retail_dataset.csv\")         # Save as CSV\n",
    "\n",
    "print(df.head())  # Show first few rows as a check\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b987b6eb",
   "metadata": {},
   "source": [
    "#### *Explanation:*\n",
    "\n",
    "Run all functions in sequence to generate, clean, enrich, and save the synthetic retail dataset, then print the first few rows for verification.\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1ee2260",
   "metadata": {},
   "source": [
    "### *Data Inspection Summary*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0f191b41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1000 entries, 0 to 999\n",
      "Data columns (total 10 columns):\n",
      " #   Column        Non-Null Count  Dtype  \n",
      "---  ------        --------------  -----  \n",
      " 0   InvoiceNo     1000 non-null   object \n",
      " 1   StockCode     1000 non-null   object \n",
      " 2   Description   980 non-null    object \n",
      " 3   Category      1000 non-null   object \n",
      " 4   Quantity      1000 non-null   int64  \n",
      " 5   InvoiceDate   1000 non-null   object \n",
      " 6   UnitPrice     1000 non-null   float64\n",
      " 7   CustomerID    1000 non-null   object \n",
      " 8   Country       990 non-null    object \n",
      " 9   CustomerName  1000 non-null   object \n",
      "dtypes: float64(1), int64(1), object(8)\n",
      "memory usage: 78.3+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c2e90a9",
   "metadata": {},
   "source": [
    "#### *Explanation:*\n",
    "\n",
    "- Dataset has 1000 rows and 10 columns.\n",
    "- Columns include IDs, product info, transaction details, and customer info.\n",
    "- Data types: mostly strings (object), Quantity (int), UnitPrice (float), InvoiceDate as string.\n",
    "- Missing values: Description (2%), Country (1%).\n",
    "- InvoiceDate should be converted to datetime for analysis.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96d4c5bb",
   "metadata": {},
   "source": [
    "___\n",
    "### *Handle Missing Values and Convert InvoiceDate to Datetime - the generated data*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "96816ca9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1000 entries, 0 to 999\n",
      "Data columns (total 10 columns):\n",
      " #   Column        Non-Null Count  Dtype         \n",
      "---  ------        --------------  -----         \n",
      " 0   InvoiceNo     1000 non-null   object        \n",
      " 1   StockCode     1000 non-null   object        \n",
      " 2   Description   1000 non-null   object        \n",
      " 3   Category      1000 non-null   object        \n",
      " 4   Quantity      1000 non-null   int64         \n",
      " 5   InvoiceDate   1000 non-null   datetime64[ns]\n",
      " 6   UnitPrice     1000 non-null   float64       \n",
      " 7   CustomerID    1000 non-null   object        \n",
      " 8   Country       1000 non-null   object        \n",
      " 9   CustomerName  1000 non-null   object        \n",
      "dtypes: datetime64[ns](1), float64(1), int64(1), object(7)\n",
      "memory usage: 78.3+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "def clean_and_convert(df):\n",
    "\n",
    "    #Handle missing values and convert InvoiceDate to datetime.\n",
    "\n",
    "    # Fill missing values\n",
    "    df['Description'] = df['Description'].fillna('Unknown Product')\n",
    "    df['Country'] = df['Country'].fillna('Unknown Country')\n",
    "\n",
    "    # Convert InvoiceDate to datetime\n",
    "    df['InvoiceDate'] = pd.to_datetime(df['InvoiceDate'], errors='coerce')\n",
    "\n",
    "    return df\n",
    "\n",
    "# Usage\n",
    "df = clean_and_convert(df)\n",
    "print(df.info())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24081611",
   "metadata": {},
   "source": [
    "#### *Explanation:*\n",
    "\n",
    "- Fill missing values in the **Description** column with the string `'Unknown Product'` to avoid nulls that might break analysis or database constraints.\n",
    "- Fill missing values in the **Country** column with `'Unknown Country'` for the same reason.\n",
    "- Convert the **InvoiceDate** column from string to pandas datetime format to enable time-based operations.\n",
    "- Use `errors='coerce'` to convert invalid date strings into `NaT` (Not a Time), which represents missing datetime values.\n",
    "\n",
    "___\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12cc1e11",
   "metadata": {},
   "source": [
    "## **2. Transformation**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b269089c",
   "metadata": {},
   "source": [
    "### *Calculate TotalSales Column*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4bff0628",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_total_sales(df):\n",
    "    df['TotalSales'] = df['Quantity'] * df['UnitPrice']\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0b9d683",
   "metadata": {},
   "source": [
    "#### *Explanation:*\n",
    "\n",
    "Create a new column `TotalSales` by multiplying `Quantity` and `UnitPrice` for each record. This provides the sales revenue per transaction.\n",
    "\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0eb26fa",
   "metadata": {},
   "source": [
    "### *Remove Outliers*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "76dbc8af",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_outliers(df):\n",
    "    cleaned_df = df[(df['Quantity'] >= 0) & (df['UnitPrice'] > 0)]\n",
    "    return cleaned_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93bf5ec3",
   "metadata": {},
   "source": [
    "#### *Explanation:*\n",
    "\n",
    "Filter out rows where `Quantity` is negative or `UnitPrice` is zero or negative to ensure data accuracy and quality.\n",
    "\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeebff43",
   "metadata": {},
   "source": [
    "### *Filter Sales in the Last Year*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1889222a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "def filter_last_year_sales(df, reference_date=datetime(2025, 8, 12)):\n",
    "    one_year_ago = reference_date.replace(year=reference_date.year - 1)\n",
    "    filtered_df = df[df['InvoiceDate'] >= one_year_ago]\n",
    "    return filtered_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61c27071",
   "metadata": {},
   "source": [
    "#### *Explanation:*\n",
    "\n",
    "Keep only transactions within the last year, using August 12, 2025, as the reference date. This focuses analysis on recent sales activity.\n",
    "\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a439887",
   "metadata": {},
   "source": [
    "### *Create Customer Summary*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "43b8d6a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_customer_summary(df):\n",
    "    customer_summary = df.groupby('CustomerID').agg({\n",
    "        'TotalSales': 'sum',\n",
    "        'Country': 'first'  \n",
    "    }).reset_index()\n",
    "    customer_summary.rename(columns={'TotalSales': 'TotalPurchases'}, inplace=True)\n",
    "    return customer_summary\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e2303c3",
   "metadata": {},
   "source": [
    "#### *Explanation:*\n",
    "\n",
    "Group data by `CustomerID` to create a summary table that aggregates total purchases per customer and retains their country information.\n",
    "\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71cb527e",
   "metadata": {},
   "source": [
    "### *Transform Pipeline*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4d115046",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_pipeline(df):\n",
    "    df = add_total_sales(df)\n",
    "    df = remove_outliers(df)\n",
    "    df = filter_last_year_sales(df)\n",
    "    customer_summary = create_customer_summary(df)\n",
    "    return df, customer_summary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "57bf4bed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1000 entries, 0 to 999\n",
      "Data columns (total 10 columns):\n",
      " #   Column        Non-Null Count  Dtype         \n",
      "---  ------        --------------  -----         \n",
      " 0   InvoiceNo     1000 non-null   object        \n",
      " 1   StockCode     1000 non-null   object        \n",
      " 2   Description   1000 non-null   object        \n",
      " 3   Category      1000 non-null   object        \n",
      " 4   Quantity      1000 non-null   int64         \n",
      " 5   InvoiceDate   1000 non-null   datetime64[ns]\n",
      " 6   UnitPrice     1000 non-null   float64       \n",
      " 7   CustomerID    1000 non-null   object        \n",
      " 8   Country       1000 non-null   object        \n",
      " 9   CustomerName  1000 non-null   object        \n",
      "dtypes: datetime64[ns](1), float64(1), int64(1), object(7)\n",
      "memory usage: 78.3+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1851460",
   "metadata": {},
   "source": [
    "#### *Explanation:*\n",
    "\n",
    "Run all transformation functions sequentially to produce cleaned, enriched sales data and a customer summary dimension table, ready for loading or further analysis.\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5766f66",
   "metadata": {},
   "source": [
    "## **3. Load**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0b17af70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tables created successfully!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded successfully into SQLite!\n"
     ]
    }
   ],
   "source": [
    "import sqlite3\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "# Connect to (or create) the SQLite database\n",
    "conn = sqlite3.connect('retail_dw.db')\n",
    "cursor = conn.cursor()\n",
    "\n",
    "# Step 1: Create tables using your saved .sql script\n",
    "with open('retail_dw.sql', 'r') as f:\n",
    "    sql_script = f.read()\n",
    "cursor.executescript(sql_script)\n",
    "print(\"Tables created successfully!\")\n",
    "\n",
    "# Step 2: Load data into dimension tables\n",
    "#  for dim_date\n",
    "df_date = df[['InvoiceDate']].drop_duplicates().copy()\n",
    "df_date['full_date'] = df_date['InvoiceDate']\n",
    "df_date['day'] = df_date['InvoiceDate'].dt.day\n",
    "df_date['month'] = df_date['InvoiceDate'].dt.month\n",
    "df_date['quarter'] = df_date['InvoiceDate'].dt.quarter\n",
    "df_date['year'] = df_date['InvoiceDate'].dt.year\n",
    "df_date.reset_index(drop=True, inplace=True)\n",
    "df_date['date_id'] = df_date.index + 1  # create PK\n",
    "\n",
    "# Then insert into SQLite\n",
    "df_date_to_insert = df_date[['date_id', 'full_date', 'day', 'month', 'quarter', 'year']]\n",
    "\n",
    "# for dim_customer\n",
    "# Prepare dim_customer DataFrame to match SQLite table\n",
    "df_customer = df[['CustomerID','Country']].drop_duplicates().copy()\n",
    "df_customer['customer_id'] = range(1, len(df_customer)+1)\n",
    "df_customer = df_customer.rename(columns={\n",
    "    'CustomerID': 'customer_code',   # match the table column\n",
    "    'Country': 'country'\n",
    "})\n",
    "# Reorder columns to match the table\n",
    "df_customer = df_customer[['customer_id','customer_code','country']]\n",
    "df_customer.to_sql('dim_customer', conn, if_exists='append', index=False)\n",
    "\n",
    "#  for dim_product\n",
    "# Prepare dim_product DataFrame to match SQLite table\n",
    "df_product = df[['StockCode','Description','Category']].drop_duplicates().copy()\n",
    "df_product['product_id'] = range(1, len(df_product)+1)\n",
    "\n",
    "# Rename columns to match SQLite table\n",
    "df_product = df_product.rename(columns={\n",
    "    'StockCode': 'stock_code',\n",
    "    'Description': 'name',\n",
    "    'Category': 'category'\n",
    "})\n",
    "\n",
    "# Reorder columns to match the table\n",
    "df_product = df_product[['product_id','stock_code','name','category']]\n",
    "\n",
    "# Load into SQLite\n",
    "df_product.to_sql('dim_product', conn, if_exists='append', index=False)\n",
    "\n",
    "\n",
    "# Step 3: Load data into fact table\n",
    "df_fact = df.copy()\n",
    "\n",
    "# Merge with date dimension\n",
    "df_fact = df_fact.merge(df_date[['date_id', 'InvoiceDate']], \n",
    "                        left_on='InvoiceDate', right_on='InvoiceDate', how='left')\n",
    "\n",
    "# Merge with customer dimension\n",
    "df_fact = df_fact.merge(df_customer[['customer_id', 'customer_code']], \n",
    "                        left_on='CustomerID', right_on='customer_code', how='left')\n",
    "\n",
    "# Merge with product dimension\n",
    "df_fact = df_fact.merge(df_product[['product_id', 'stock_code']], \n",
    "                        left_on='StockCode', right_on='stock_code', how='left')\n",
    "\n",
    "# Calculate TotalSales\n",
    "df_fact['TotalSales'] = df_fact['Quantity'] * df_fact['UnitPrice']\n",
    "\n",
    "## Select & rename columns to match fact_sales schema\n",
    "df_fact_final = df_fact[['InvoiceNo','date_id','product_id','customer_id','Quantity','UnitPrice','TotalSales']]\n",
    "df_fact_final = df_fact_final.rename(columns={\n",
    "    'InvoiceNo': 'invoice_no',\n",
    "    'Quantity': 'quantity',\n",
    "    'UnitPrice': 'unit_price',\n",
    "    'TotalSales': 'total_sales'\n",
    "})\n",
    "# Load into SQLite\n",
    "df_fact_final.to_sql('fact_sales', conn, if_exists='append', index=False)\n",
    "\n",
    "conn.commit()\n",
    "conn.close()\n",
    "print(\"Data loaded successfully into SQLite!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
