{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "911df99f",
   "metadata": {},
   "source": [
    "___\n",
    "## 1.2 ETL Process Implementation\n",
    "\n",
    "**Dataset:** Synthetic data designed to mimic the structure and scale of the target dataset with similar columns:  \n",
    "\n",
    "| Column       | Description                                      |\n",
    "|--------------|--------------------------------------------------|\n",
    "| InvoiceNo    | Unique invoice identifier                        |\n",
    "| StockCode    | Product code                                     |\n",
    "| Description  | Product description                              |\n",
    "| Quantity     | Number of items purchased                        |\n",
    "| InvoiceDate  | Date of purchase                                 |\n",
    "| UnitPrice    | Price per item                                   |\n",
    "| CustomerID   | Unique customer identifier                        |\n",
    "| Country      | Customer's country                               |\n",
    "\n",
    "**Dataset Features:**  \n",
    "- Row count: ~500–1000 (practicality)  \n",
    "- Quantities: 1–50, Prices: 1–100  \n",
    "- Dates span 2 years  \n",
    "- 100 unique customers  \n",
    "- 5–10 countries  \n",
    "- Includes missing values, categorical columns, and outliers for Quantity and UnitPrice  \n",
    "- Seeded for reproducibility  \n",
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "64366705",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "from datetime import datetime, timedelta\n",
    "from faker import Faker\n",
    "import sqlite3\n",
    "import logging\n",
    "\n",
    "# ===== Logging Setup =====\n",
    "logging.basicConfig(level=logging.INFO, format=\"%(asctime)s - %(levelname)s - %(message)s\")\n",
    "\n",
    "# ===== Reproducibility =====\n",
    "np.random.seed(42)\n",
    "random.seed(42)\n",
    "\n",
    "# ===== Config =====\n",
    "NUM_ROWS = 1000\n",
    "NUM_CUSTOMERS = 100\n",
    "START_DATE = datetime(2023, 8, 12)\n",
    "END_DATE = datetime(2025, 8, 11)\n",
    "COUNTRIES = [\"United Kingdom\", \"Germany\", \"France\", \"Spain\", \"Netherlands\", \"Italy\", \"Norway\", \"Portugal\"]\n",
    "PRODUCTS = [\n",
    "    (\"E001\", \"Wireless Mouse\", \"Electronics\"),\n",
    "    (\"E002\", \"Bluetooth Headphones\", \"Electronics\"),\n",
    "    (\"E003\", \"Smartphone Charger\", \"Electronics\"),\n",
    "    (\"C001\", \"Men's T-Shirt\", \"Clothing\"),\n",
    "    (\"C002\", \"Women's Jeans\", \"Clothing\"),\n",
    "    (\"C003\", \"Baseball Cap\", \"Clothing\"),\n",
    "    (\"H001\", \"Ceramic Mug\", \"Home Goods\"),\n",
    "    (\"H002\", \"Wall Clock\", \"Home Goods\"),\n",
    "    (\"H003\", \"LED Desk Lamp\", \"Home Goods\"),\n",
    "    (\"T001\", \"Stuffed Bear\", \"Toys\"),\n",
    "    (\"T002\", \"Building Blocks Set\", \"Toys\"),\n",
    "    (\"T003\", \"RC Car\", \"Toys\"),\n",
    "]\n",
    "\n",
    "# ===== Helper Functions =====\n",
    "def random_date(start_date, end_date):\n",
    "    delta = end_date - start_date\n",
    "    return start_date + timedelta(\n",
    "        days=random.randint(0, delta.days),\n",
    "        seconds=random.randint(0, 86400)\n",
    "    )\n",
    "\n",
    "def generate_base_data(num_rows):\n",
    "    data = []\n",
    "    for _ in range(num_rows):\n",
    "        invoice_no = f\"INV{random.randint(10000, 99999)}\"\n",
    "        stock_code, description, category = random.choice(PRODUCTS)\n",
    "        quantity = random.randint(1, 50)\n",
    "        invoice_date = random_date(START_DATE, END_DATE)\n",
    "        unit_price = round(random.uniform(1, 100), 2)\n",
    "        customer_id = f\"CUST{random.randint(1, NUM_CUSTOMERS)}\"\n",
    "        country = random.choice(COUNTRIES)\n",
    "        data.append([invoice_no, stock_code, description, category, quantity, invoice_date, unit_price, customer_id, country])\n",
    "    columns = [\"InvoiceNo\", \"StockCode\", \"Description\", \"Category\", \"Quantity\", \"InvoiceDate\", \"UnitPrice\", \"CustomerID\", \"Country\"]\n",
    "    return pd.DataFrame(data, columns=columns)\n",
    "\n",
    "def inject_missing_values(df, desc_frac=0.02, country_frac=0.01):\n",
    "    df.loc[df.sample(frac=desc_frac).index, \"Description\"] = np.nan\n",
    "    df.loc[df.sample(frac=country_frac).index, \"Country\"] = np.nan\n",
    "    return df\n",
    "\n",
    "def inject_outliers(df, neg_qty_frac=0.01, zero_price_frac=0.01):\n",
    "    df.loc[df.sample(frac=neg_qty_frac).index, \"Quantity\"] *= -1\n",
    "    df.loc[df.sample(frac=zero_price_frac).index, \"UnitPrice\"] = 0\n",
    "    return df\n",
    "\n",
    "def save_dataset(df, filename):\n",
    "    df.to_csv(filename, index=False)\n",
    "\n",
    "def generate_customer_names(num_customers):\n",
    "    fake = Faker()\n",
    "    return {f\"CUST{i}\": fake.name() for i in range(1, num_customers + 1)}\n",
    "\n",
    "def assign_customer_names(df, customer_names):\n",
    "    df['CustomerName'] = df['CustomerID'].map(customer_names)\n",
    "    return df\n",
    "\n",
    "def clean_and_convert(df):\n",
    "    df['Description'] = df['Description'].fillna('Unknown Product')\n",
    "    df['Country'] = df['Country'].fillna('Unknown Country')\n",
    "    df['InvoiceDate'] = pd.to_datetime(df['InvoiceDate'], errors='coerce')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b580fc65",
   "metadata": {},
   "source": [
    "___\n",
    "### 1.2.1 Extract\n",
    "- Python (pandas & Faker) was used to generate the synthetic dataset as a DataFrame.  \n",
    "- Missing values handled for `Description` and `Country`.  \n",
    "- Data types corrected, e.g., `InvoiceDate` converted to datetime. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83b693d5",
   "metadata": {},
   "source": [
    "### 1.2.2 Transform\n",
    "\n",
    "**Transformations Applied:**  \n",
    "- Added a new column: `TotalSales = Quantity * UnitPrice`  \n",
    "- Filtered data for sales in the last year (assuming current date = 2025-08-12)  \n",
    "- Handled outliers by removing rows where `Quantity <= 0` or `UnitPrice <= 0` "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "752ab56c",
   "metadata": {},
   "source": [
    "### 1.2.3 Load\n",
    "\n",
    "**Loading Process:**  \n",
    "- Used `sqlite3` in Python to create a database  \n",
    "- Loaded data into:\n",
    "\n",
    "  * 1 Fact Table: `SalesFact`  \n",
    "  * 3 Dimension Tables: `ProductDim`, `CustomerDim`, `TimeDim` \n",
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d29514c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-14 23:46:38,674 - INFO - Starting ETL process...\n",
      "2025-08-14 23:46:38,730 - INFO - Synthetic dataset exported as 'synthetic_retail_dataset.csv'\n",
      "2025-08-14 23:46:38,731 - INFO - Rows after extraction: 1000\n",
      "2025-08-14 23:46:38,748 - INFO - Transformed dataset exported as 'transformed_retail_dataset.csv'\n",
      "2025-08-14 23:46:38,750 - INFO - Rows after transformation: 493\n",
      "2025-08-14 23:46:38,751 - INFO - Loading data into SQLite database using external schema...\n",
      "2025-08-14 23:46:38,994 - INFO - Data loaded successfully into SQLite database.\n",
      "2025-08-14 23:46:38,996 - INFO - ETL process completed: only synthetic, transformed, and .db exported.\n"
     ]
    }
   ],
   "source": [
    "# ===== ETL Process: Export Only .db, Transformed Data, Synthetic Data =====\n",
    "def run_etl_export_only():\n",
    "    try:\n",
    "        logging.info(\"Starting ETL process...\")\n",
    "\n",
    "        # === Extract (Synthetic Data) ===\n",
    "        df_synthetic = generate_base_data(NUM_ROWS)\n",
    "        df_synthetic = inject_missing_values(df_synthetic)\n",
    "        df_synthetic = inject_outliers(df_synthetic)\n",
    "        customer_names = generate_customer_names(df_synthetic['CustomerID'].nunique())\n",
    "        df_synthetic = assign_customer_names(df_synthetic, customer_names)\n",
    "\n",
    "        # Handle missing values & convert data types\n",
    "        df_synthetic['Description'] = df_synthetic['Description'].fillna('Unknown Product')\n",
    "        df_synthetic['Country'] = df_synthetic['Country'].fillna('Unknown Country')\n",
    "        df_synthetic['InvoiceDate'] = pd.to_datetime(df_synthetic['InvoiceDate'], errors='coerce')\n",
    "\n",
    "        # Save synthetic data\n",
    "        df_synthetic.to_csv(\"synthetic_retail_dataset.csv\", index=False)\n",
    "        logging.info(\"Synthetic dataset exported as 'synthetic_retail_dataset.csv'\")\n",
    "        logging.info(f\"Rows after extraction: {len(df_synthetic)}\")\n",
    "        # === Transform (Cleaned and Filtered Data) ===\n",
    "        df_transformed = clean_and_convert(df_synthetic.copy())\n",
    "        df_transformed['TotalSales'] = df_transformed['Quantity'] * df_transformed['UnitPrice']\n",
    "        df_transformed = df_transformed[df_transformed['Quantity'] > 0]\n",
    "        df_transformed = df_transformed[df_transformed['UnitPrice'] > 0]\n",
    "\n",
    "        # Filter last 12 months\n",
    "        current_date = pd.Timestamp(\"2025-08-12\")\n",
    "        one_year_ago = current_date - pd.DateOffset(years=1)\n",
    "        df_transformed = df_transformed[(df_transformed['InvoiceDate'] >= one_year_ago) & \n",
    "                                        (df_transformed['InvoiceDate'] <= current_date)]\n",
    "\n",
    "        # Save transformed data\n",
    "        df_transformed.to_csv(\"transformed_retail_dataset.csv\", index=False)\n",
    "        logging.info(\"Transformed dataset exported as 'transformed_retail_dataset.csv'\")\n",
    "        logging.info(f\"Rows after transformation: {len(df_transformed)}\")   \n",
    "        \n",
    "        # === Load ===\n",
    "        logging.info(\"Loading data into SQLite database using external schema...\")\n",
    "\n",
    "        conn = sqlite3.connect(\"retail.db\")\n",
    "        cur = conn.cursor()\n",
    "\n",
    "        # Read schema from external SQL file\n",
    "        with open(\"Schema2.sql\", \"r\") as f:\n",
    "            schema_sql = f.read()\n",
    "\n",
    "        cur.executescript(schema_sql)\n",
    "\n",
    "        # Insert into dimension tables\n",
    "        customer_dim = df_transformed[['CustomerID', 'CustomerName', 'Country']].drop_duplicates()\n",
    "        customer_dim.to_sql('CustomerDim', conn, if_exists='append', index=False)\n",
    "\n",
    "        product_dim = df_transformed[['StockCode', 'Description', 'Category']].drop_duplicates()\n",
    "        product_dim.to_sql('ProductDim', conn, if_exists='append', index=False)\n",
    "\n",
    "        # Merge keys for fact table\n",
    "        cust_keys = pd.read_sql(\"SELECT CustomerKey, CustomerID FROM CustomerDim\", conn)\n",
    "        prod_keys = pd.read_sql(\"SELECT ProductKey, StockCode FROM ProductDim\", conn)\n",
    "        fact_df = df_transformed.merge(cust_keys, on='CustomerID').merge(prod_keys, on='StockCode')\n",
    "        fact_df = fact_df[['InvoiceNo', 'InvoiceDate', 'Quantity', 'UnitPrice', 'CustomerKey', 'ProductKey']]\n",
    "        fact_df.to_sql('SalesFact', conn, if_exists='append', index=False)\n",
    "\n",
    "        conn.commit()\n",
    "        conn.close()\n",
    "        logging.info(\"Data loaded successfully into SQLite database.\")\n",
    "\n",
    "\n",
    "        logging.info(\"ETL process completed: only synthetic, transformed, and .db exported.\")\n",
    "\n",
    "    except Exception as e:\n",
    "        logging.error(f\"ETL process failed: {e}\")\n",
    "\n",
    "# ===== Run ETL =====\n",
    "if __name__ == \"__main__\":\n",
    "    run_etl_export_only()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a64ddc12",
   "metadata": {},
   "source": [
    "___\n",
    "### 1.2.4 Full ETL Function\n",
    "\n",
    "**Overview:**  \n",
    "- Modular ETL function that can be applied to any dataset  \n",
    "- Performs **full ETL** by calling `run_etl_export_only()`  \n",
    "- Logs the number of rows processed at each stage  \n",
    "- Handles errors gracefully  \n",
    "- Exports:\n",
    "\n",
    "  **Synthetic dataset** \n",
    "  \n",
    "  **Transformed dataset**\n",
    "  \n",
    "  **SQLite database** \n",
    "___"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
